{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oR2DF1nC1s6V"
      },
      "source": [
        "pip install google-cloud-automl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bka3031WJ-DH"
      },
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]= r\"/content/logo-detection-324201-dcb622a7644d.json\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJUYxJr6fqL1"
      },
      "source": [
        "### Deploy Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElkmD5oj7FPZ",
        "outputId": "5a855d93-d178-4f53-c630-a365ba0f0dcd"
      },
      "source": [
        "# Launch LED Counter Detection\n",
        "from google.cloud import automl\n",
        "\n",
        "# TODO(developer): Uncomment and set the following variables\n",
        "project_id = \"logo-detection-324201\"\n",
        "model_id = \"IOD925900940773425152\"\n",
        "\n",
        "client = automl.AutoMlClient()\n",
        "# Get the full path of the model.\n",
        "model_full_id = client.model_path(project_id, \"us-central1\", model_id)\n",
        "response = client.deploy_model(name=model_full_id)\n",
        "\n",
        "print(f\"Hotlink LED Counter Model deployment finished. {response.result()}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model deployment finished. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFRfnEUgEI2G",
        "outputId": "3edbad42-3588-4da5-e8ca-2dda2d1d2cb4"
      },
      "source": [
        "# Launch Logo Detection\n",
        "project_id = \"logo-detection-324201\"\n",
        "model_id = \"IOD447956430318731264\"\n",
        "\n",
        "client = automl.AutoMlClient()\n",
        "# Get the full path of the model.\n",
        "model_full_id = client.model_path(project_id, \"us-central1\", model_id)\n",
        "response = client.deploy_model(name=model_full_id)\n",
        "\n",
        "print(f\"Hotlink Logo Model deployment finished. {response.result()}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hotlink Logo Model deployment finished. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKiujkf_fm6a"
      },
      "source": [
        "### Run Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRqRcgcwKINd",
        "outputId": "7d996ba1-5c01-4420-f587-9d7ece5aa5cd"
      },
      "source": [
        "# RUN PREDICTION - HOTLINK LED Counter\n",
        "def predict1(project_id, model_id, file_path):\n",
        "    \"\"\"Predict.\"\"\"\n",
        "    # [START automl_vision_object_detection_predict]\n",
        "    from google.cloud import automl\n",
        "\n",
        "    # TODO(developer): Uncomment and set the following variables\n",
        "    project_id = \"logo-detection-324201\"\n",
        "    model_id = \"IOD925900940773425152\"\n",
        "    file_path = \"/content/hotlinkcounter (1)\"\n",
        "\n",
        "    prediction_client = automl.PredictionServiceClient()\n",
        "\n",
        "    # Get the full path of the model.\n",
        "    model_full_id = automl.AutoMlClient.model_path(project_id, \"us-central1\", model_id)\n",
        "\n",
        "    # Read the file.\n",
        "    with open(file_path, \"rb\") as content_file:\n",
        "        content = content_file.read()\n",
        "\n",
        "    image = automl.Image(image_bytes=content)\n",
        "    payload = automl.ExamplePayload(image=image)\n",
        "\n",
        "    # params is additional domain-specific parameters.\n",
        "    # score_threshold is used to filter the result\n",
        "    # https://cloud.google.com/automl/docs/reference/rpc/google.cloud.automl.v1#predictrequest\n",
        "    params = {\"score_threshold\": \"0.8\"}\n",
        "\n",
        "    request = automl.PredictRequest(name=model_full_id, payload=payload, params=params)\n",
        "\n",
        "    Counter_response = prediction_client.predict(request=request)\n",
        "\n",
        "    count = 0\n",
        "\n",
        "    print(\"Prediction results:\")\n",
        "    for result in Counter_response.payload:\n",
        "        print(\"Predicted class name: {}\".format(result.display_name))\n",
        "        print(\"Predicted class score: {}\".format(result.image_object_detection.score))\n",
        "        bounding_box = result.image_object_detection.bounding_box\n",
        "        print(\"Normalized Vertices:\")\n",
        "\n",
        "        for vertex in bounding_box.normalized_vertices:\n",
        "            print(\"\\tX: {}, Y: {}\".format(vertex.x, vertex.y))\n",
        "          \n",
        "        count += 1\n",
        "        if count > 0:\n",
        "          print(result.display_name + \": \", count)\n",
        "\n",
        "predict1(\"\",\"\",\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction results:\n",
            "Predicted class name: Hotlink LED Counter\n",
            "Predicted class score: 0.9992972612380981\n",
            "Normalized Vertices:\n",
            "\tX: 0.03720211982727051, Y: 0.41064807772636414\n",
            "\tX: 0.9373325109481812, Y: 0.9256527423858643\n",
            "Hotlink LED Counter:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuHLeNjUfKHg",
        "outputId": "75dc6759-6d81-4e2a-8a91-98fd5acae17e"
      },
      "source": [
        "# RUN PREDICTION - HOTLINK logo\n",
        "def predict2(project_id, model_id, file_path):\n",
        "    \"\"\"Predict.\"\"\"\n",
        "    # [START automl_vision_object_detection_predict]\n",
        "    from google.cloud import automl\n",
        "\n",
        "    # TODO(developer): Uncomment and set the following variables\n",
        "    project_id = \"logo-detection-324201\"\n",
        "    model_id = \"IOD447956430318731264\"\n",
        "    file_path = \"/content/hotlinkcounter (1)\"\n",
        "\n",
        "    prediction_client = automl.PredictionServiceClient()\n",
        "\n",
        "    # Get the full path of the model.\n",
        "    model_full_id = automl.AutoMlClient.model_path(project_id, \"us-central1\", model_id)\n",
        "\n",
        "    # Read the file.\n",
        "    with open(file_path, \"rb\") as content_file:\n",
        "        content = content_file.read()\n",
        "\n",
        "    image = automl.Image(image_bytes=content)\n",
        "    payload = automl.ExamplePayload(image=image)\n",
        "\n",
        "    # params is additional domain-specific parameters.\n",
        "    # score_threshold is used to filter the result\n",
        "    # https://cloud.google.com/automl/docs/reference/rpc/google.cloud.automl.v1#predictrequest\n",
        "    params = {\"score_threshold\": \"0.8\"}\n",
        "\n",
        "    request = automl.PredictRequest(name=model_full_id, payload=payload, params=params)\n",
        "\n",
        "    Logo_response = prediction_client.predict(request=request)\n",
        "\n",
        "    count = 0\n",
        "\n",
        "    print(\"Prediction results:\")\n",
        "    for result in Logo_response.payload:\n",
        "        print(\"Predicted class name: {}\".format(result.display_name))\n",
        "        print(\"Predicted class score: {}\".format(result.image_object_detection.score))\n",
        "        bounding_box = result.image_object_detection.bounding_box\n",
        "        print(\"Normalized Vertices:\")\n",
        "\n",
        "        for vertex in bounding_box.normalized_vertices:\n",
        "            print(\"\\tX: {}, Y: {}\".format(vertex.x, vertex.y))\n",
        "          \n",
        "        count += 1\n",
        "        if count > 0:\n",
        "          print(result.display_name + \": \", count)\n",
        "\n",
        "predict2(\"\",\"\",\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction results:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "Vl2wRT9cfuyF",
        "outputId": "57a15262-486d-40b7-9e93-29161698faf3"
      },
      "source": [
        "if result.display_name \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-1e6c6c7b7859>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mresult1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCounter_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mbounding_box1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_object_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbounding_box\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mvertex1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mvertex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbounding_box1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalized_vertices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvertex1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\tX: {}, Y: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvertex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Counter_response' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BLITIGyfhXN"
      },
      "source": [
        "### Undeploy Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48JpW73qKSBN",
        "outputId": "7de0c1f5-f7cc-4ea5-c57c-06949cbe5d00"
      },
      "source": [
        "# UNDEPLOY LED Counter MODEL\n",
        "from google.cloud import automl\n",
        "\n",
        "# TODO(developer): Uncomment and set the following variables\n",
        "project_id = \"logo-detection-324201\"\n",
        "model_id = \"IOD925900940773425152\"\n",
        "client = automl.AutoMlClient()\n",
        "# Get the full path of the model.\n",
        "model_full_id = client.model_path(project_id, \"us-central1\", model_id)\n",
        "response = client.undeploy_model(name=model_full_id)\n",
        "\n",
        "print(\"Model undeployment finished. {}\".format(response.result()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model undeployment finished. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhF6YhCTXZlK",
        "outputId": "9319b144-3a55-49d4-bd16-ad7ec662c680"
      },
      "source": [
        "# UNDEPLOY Logo Detection MODEL\n",
        "from google.cloud import automl\n",
        "\n",
        "# TODO(developer): Uncomment and set the following variables\n",
        "project_id = \"logo-detection-324201\"\n",
        "model_id = \"IOD447956430318731264\"\n",
        "client = automl.AutoMlClient()\n",
        "# Get the full path of the model.\n",
        "model_full_id = client.model_path(project_id, \"us-central1\", model_id)\n",
        "response = client.undeploy_model(name=model_full_id)\n",
        "\n",
        "print(\"Model undeployment finished. {}\".format(response.result()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model undeployment finished. \n"
          ]
        }
      ]
    }
  ]
}